# --- FACMAC specific parameters ---
action_range: ~
action_selector: ~
agent: "mlp_continuous_stochastic"
obs_agent_id: True
obs_last_action: True
agent_output_type: ~
batch_size_run: 1
batch_size: 20
buffer_size: 1000
buffer_warmup: 100
discretize_actions: False
double_q: False
epsilon_decay_mode: ~
epsilon_start: ~
epsilon_finish: ~
epsilon_anneal_time: ~
exploration_mode: "gaussian"
start_steps: 50000 # Number of steps for uniform-random action selection, before running real policy. Helps exploration.
end_noise: 100000
act_noise: 0.15 # Stddev for Gaussian exploration noise added to policy at training time.
ou_theta: 0.15 # D
ou_sigma: 0.2 # D
ou_noise_scale: 0.3
final_ou_noise_scale: 0.
gamma: 0.99
grad_norm_clip: 50
learner: "facmac_learner"
critic_type: ~
mac: "maddpg_distrib_mac"
mixer: "qmix"
learn_interval: 1
lr: 0.005
critic_lr: 0.005
td_lambda: 0.8
critic_train_reps: 1
q_nstep: 0  # 0 corresponds to default Q, 1 is r + gamma*Q, etc
mixing_embed_dim: 64
skip_connections: False
gated: False
hypernet_layers: 2
hypernet_embed: 64
hyper_initialization_nonzeros: 0
name: "facmac"
n_runners: ~
n_train: 1
optimizer: "adam" # D
optimizer_epsilon: 0.000001 # D
ou_stop_episode: 1500 # training noise goes to zero after this episode
rnn_hidden_dim: 64
run_mode: ~
runner: "episode"
runner_scope: 'episodic'
target_update_interval: ~
recurrent_critic: False
target_update_mode: "soft"
target_update_tau: 0.005
test_greedy: ~
test_interval: 50000000
test_nepisode: 0
testing_on: True
t_max: 250000
save_model: True
save_model_interval: 5000
verbose: False
weight_decay: False
weight_decay_factor: 0.0001
env_args:
  state_last_action: False # critic adds last action internally
agent_return_logits: False
q_embed_dim: 1

actor_weight: 1
reg_weight: 0.0001

lr_decay_actor: True
lr_decay_critic: True
lr_decay_gamma: 0.95
lr_decay_steps: 100

l2_reg_coef: 0

target_update_interval_or_tau: 200

use_cuda: True

standardise_returns: False
standardise_rewards: False

#load_step: 561000
#checkpoint_path: "D:/MAI/TFM/TFM/results/pistonball_reward_2_actions/facmac_pettingzoo/196/models" 
#evaluate: True # Evaluate model for test_nepisode episodes and quit (no training)